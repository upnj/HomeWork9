---
title: "Home Work 9"
author: "Upendra Joshi"
format: html
editor: visual
---

Let's take the Part of the code from Home Work 8 as we used MLR model. Please note I am using the bike_data_clean dataset insead of daily_bike_data used in home work 8.

```{r}
#install.packages("baguette")
#install.packages("ranger")
library(ranger)
library(baguette)
library(tidyverse)
library(lubridate)
library(skimr)
library(dplyr)
library(tidymodels)
library(glmnet)
library(rpart)
library(rpart.plot)
library(vip)

url <- "https://www4.stat.ncsu.edu/~online/datasets/SeoulBikeData.csv"
bike_data <- read.csv(url, fileEncoding = "latin1")

# Check the data
head(bike_data)
# Clean and rename the data
bike_data_clean <- bike_data %>%
    rename(
    date = Date,
    bike_count = `Rented.Bike.Count`,
    hour = Hour,
    temperature = `Temperature..C.`,
    humidity = `Humidity...`,
    wind_speed = `Wind.speed..m.s.`,
    visibility = `Visibility..10m.`,
    dew_point = `Dew.point.temperature..C.`,
    solar_radiation = `Solar.Radiation..MJ.m2.`,
    rainfall = `Rainfall.mm.`,
    snowfall = `Snowfall..cm.`,
    seasons = Seasons,
    holiday = Holiday,
    functioning_day = `Functioning.Day`
  )


# Set seed for reproducibility
set.seed(123)

# Create initial split (75/25) stratified by seasons
bike_split <- initial_split(bike_data_clean, prop = 0.75, strata = seasons)

# Create training and testing sets
bike_train <- training(bike_split)
bike_test <- testing(bike_split)

# Create 10-fold CV split on training data
bike_folds <- vfold_cv(bike_train, v = 10)

# Check the dimensions of our splits
cat("Dimensions of datasets:\n")
cat("Full data:", nrow(bike_data_clean), "rows\n")
cat("Training set:", nrow(bike_train), "rows\n")
cat("Testing set:", nrow(bike_test), "rows\n")

# Check the structure of the CV folds
bike_folds



```

## Fitting MLR Models

First, let’s create some recipes. For the 1st recipe: • Let’s ignore the date variable for modeling (so we’ll need to remove that or give it a different ID) but use it to create a weekday/weekend (factor) variable. (See step 2 of the shinymodels tutorial! You can use step_date() then step_mutate() with a factor(if_else(…)) to create the variable. I then had to remove the intermediate variable created.) • Let’s standardize the numeric variables since their scales are pretty different. • Let’s create dummy variables for the seasons, holiday, and our new day type variable

```{r}
# Create first recipe
recipe1 <- recipe(bike_count ~ ., data = bike_train) %>%
  # Convert date to Date format
  step_mutate(date = lubridate::dmy(date)) %>%
 # Create weekday/weekend variable from date
 step_date(date, features = "dow") %>%
 step_mutate(
   day_type = factor(if_else(
     date_dow %in% c("Sat", "Sun"), 
     "weekend", 
     "weekday"
   ))
 ) %>%
 # Remove the intermediate dow variable and date
 step_rm(date_dow, date) %>%
 # Standardize numeric variables
 step_normalize(all_numeric_predictors()) %>%
 # Create dummy variables
 step_dummy(all_nominal_predictors())

# Print the recipe to check steps
print(recipe1)

# Check if recipe works by prepping it
prep(recipe1) %>%
 bake(new_data = NULL) %>%
 glimpse()
```

For the 2nd recipe: • Do the same steps as above. • Add in interactions between seasons and holiday, seasons and temp, temp and rainfall. For the seasons interactions, you can use starts_with() to create the proper interactions.

```{r}
# Create second recipe
recipe2 <- recipe(bike_count ~ ., data = bike_train) %>%
  # Convert date to Date format
  step_mutate(date = lubridate::dmy(date)) %>%
  step_date(date, features = "dow") %>%
  step_mutate(
    day_type = factor(if_else(
      date_dow %in% c("Sat", "Sun"), 
      "weekend", 
      "weekday"
    ))
  ) %>%
  step_rm(date_dow, date) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%  # Changed to one_hot encoding
  # Simplified interactions
  step_interact(terms = ~ temperature:rainfall)%>%
  # Handle rank deficiency
  step_zv(all_predictors())

# Print the recipe to check steps
print(recipe2)
# Check if recipe works and examine the results
prep(recipe2) %>%
 bake(new_data = NULL) %>%
 glimpse()

```

```{r}
# Check names of interaction terms
processed_data2 <- prep(recipe2) %>%
 bake(new_data = NULL)

cat("\nInteraction terms created:\n")
names(processed_data2)[grep("_x_", names(processed_data2))]
```

This recipe includes:

All transformations from recipe1 Interactions between:

Seasons dummy variables and holiday Seasons dummy variables and mean temperature Mean temperature and total rainfall For the 3rd recipe: • Do the same as the 2nd recipe. • Add in quadratic terms for each numeric predictor

```{r}
# Create third recipe
recipe3 <- recipe(bike_count ~ ., data = bike_train) %>%
  # Convert date to Date format
  step_mutate(date = lubridate::dmy(date)) %>%
  
  step_date(date, features = "dow") %>%
  step_mutate(
    day_type = factor(if_else(
      date_dow %in% c("Sat", "Sun"), 
      "weekend", 
      "weekday"
    ))
  ) %>%
  step_rm(date_dow, date) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%  # Changed to one_hot encoding
  step_interact(terms = ~ temperature:rainfall) %>%
  # More selective with polynomial terms
  step_poly(temperature, humidity, wind_speed, degree = 2)
   
# Print the recipe to check steps
print(recipe3)
```

```{r}
# Check if recipe works and examine the results
processed_data3 <- prep(recipe3) %>%
 bake(new_data = NULL)

# Look at the structure
glimpse(processed_data3)
```

```{r}
# Check names of quadratic terms
cat("\nQuadratic terms created:\n")
names(processed_data3)[grep("_2$", names(processed_data3))]

```

All transformations from recipe2 Quadratic terms (squared terms) for all numeric predictors:

rainfall temperature humidity wind_speed visibility dew_point solar_rad total_snowfall

Each numeric variable will now have both its linear and quadratic term, allowing for curved relationships with the response variable.

Now set up our linear model fit to use the “lm” engine. Fit the models using 10 fold CV via fit_resamples() and consider the training set CV error to choose a best model.

```{r}
# Set up linear model with lm engine
lm_model <- linear_reg() %>%
 set_engine("lm")

# Create workflows for each recipe
workflow1 <- workflow() %>%
 add_recipe(recipe1) %>%
 add_model(lm_model)

workflow2 <- workflow() %>%
 add_recipe(recipe2) %>%
 add_model(lm_model)

workflow3 <- workflow() %>%
 add_recipe(recipe3) %>%
 add_model(lm_model)

# Fit models using 10-fold CV
set.seed(123)  # for reproducibility


cv_results1 <- workflow1 %>%
  fit_resamples(
    resamples = bike_folds,
    metrics = metric_set(rmse, rsq, mae),
    control = control_resamples(save_pred = TRUE)
  )

# Fit model 2
cv_results2 <- workflow2 %>%
  fit_resamples(
    resamples = bike_folds,
    metrics = metric_set(rmse, rsq, mae),
    control = control_resamples(save_pred = TRUE,
                                extract = function(x) predict(x, rankdeficient = "NA"))
  )

# Fit model 3
cv_results3 <- workflow3 %>%
  fit_resamples(
    resamples = bike_folds,
    metrics = metric_set(rmse, rsq, mae),
    control = control_resamples(save_pred = TRUE,
                                extract = function(x) predict(x, rankdeficient = "NA"))
  )

# Collect and compare CV results
cat("Model 1 CV Results:\n")
collect_metrics(cv_results1)

cat("\nModel 2 CV Results:\n")
collect_metrics(cv_results2)

cat("\nModel 3 CV Results:\n")
collect_metrics(cv_results3)


# Compare models side by side

combined_results <- bind_rows(
  collect_metrics(cv_results1) %>% mutate(model = "Model 1"),
  collect_metrics(cv_results2) %>% mutate(model = "Model 2"),
  collect_metrics(cv_results3) %>% mutate(model = "Model 3")
)


```

To determine the best model among the three sets of results, we need to compare their performance metrics. Let's focus on the RMSE (Root Mean Squared Error) and R-squared values, as they provide a good indication of the model's predictive accuracy and goodness of fit.

Model 1:

RMSE: 432.4479006 R-squared: 0.5515968

Model 2:

RMSE: 432.6638342 R-squared: 0.5511493

Model 3:

RMSE: 421.644854 R-squared: 0.573702

Comparing the three models:

Model 3 has the lowest RMSE value of 421.644854, which indicates that it has the smallest average prediction error among the three models. A lower RMSE suggests better predictive accuracy. Model 3 also has the highest R-squared value of 0.573702, meaning that it explains the highest proportion of variance in the target variable among the three models. A higher R-squared indicates a better fit of the model to the data.

Based on these results, Model 3 appears to be the best-performing model among the three. It has the lowest RMSE and the highest R-squared, suggesting that it has better predictive accuracy and explains more variability in the target variable compared to the other two models. However, it's important to note that the differences in performance metrics between the models are relatively small. The RMSE values are close to each other, and the R-squared values are also similar.

For the homework 9 I will used model 3

```{r}
# Define the model recipes and workflows

# LASSO model with pre-processing steps

lasso_recipe <- recipe(bike_count ~ ., data = bike_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())  # Handle categorical variables

lasso_model <- linear_reg(penalty = tune(), mixture = 1) %>%
  set_engine("glmnet")

lasso_workflow <- workflow() %>%
  add_recipe(lasso_recipe) %>%
  add_model(lasso_model)

# Regression Tree model with preprocessing steps
tree_recipe <- recipe(bike_count ~ ., data = bike_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

tree_model <- decision_tree(cost_complexity = tune(), min_n = tune()) %>%
  set_engine("rpart") %>%
  set_mode("regression")

tree_workflow <- workflow() %>%
  add_recipe(tree_recipe) %>%
  add_model(tree_model)


# Bagged Tree model with preprocessing steps
bagged_recipe <- recipe(bike_count ~ ., data = bike_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

# Correct the model specification (without `trees` argument)
bagged_model <- bag_tree(tree_depth = 5, cost_complexity = tune(), min_n = tune()) %>%   
  set_engine("rpart") %>% 
  set_mode("regression")

bagged_workflow <- workflow() %>%
  add_recipe(bagged_recipe) %>%
  add_model(bagged_model)

# Random Forest model with preprocessing steps
rf_recipe <- recipe(bike_count ~ ., data = bike_train) %>%
  step_normalize(all_numeric_predictors()) %>%
  step_dummy(all_nominal_predictors())

rf_model <- rand_forest(mtry = tune(), min_n = tune(), trees = 5) %>%
  set_engine("ranger") %>%
  set_mode("regression")

rf_workflow <- workflow() %>%
  add_recipe(rf_recipe) %>%
  add_model(rf_model)

# Define the minimal tuning grids for all models
lasso_grid_minimal <- expand.grid(penalty = 10^seq(-3, -1, length.out = 3))
tree_grid_minimal <- expand.grid(cost_complexity = 10^seq(-2, -1, length.out = 2),
                                 min_n = c(5, 10))
rf_grid_minimal <- expand.grid(mtry = c(2, 4), min_n = c(5, 10))

# Define an extremely small tuning grid for the Bagged Tree model
bagged_grid_fast <- expand.grid(cost_complexity = 10^-2,
                                min_n = c(5))

# Create a smaller set of resamples for faster tuning
set.seed(123)
bike_folds_fast <- vfold_cv(bike_train, v = 3)

# Tune the models
lasso_tuned <- tune_grid(
  lasso_workflow,
  resamples = bike_folds_fast,
  grid = lasso_grid_minimal,
  metrics = metric_set(rmse, rsq, mae)
)

tree_tuned <- tune_grid(
  tree_workflow,
  resamples = bike_folds_fast,
  grid = tree_grid_minimal,
  metrics = metric_set(rmse, rsq, mae)
)

bagged_tuned <- tune_grid(
  bagged_workflow,
  resamples = bike_folds_fast,
  grid = bagged_grid_fast,
  metrics = metric_set(rmse, rsq, mae)
)

rf_tuned <- tune_grid(
  rf_workflow,
  resamples = bike_folds_fast,
  grid = rf_grid_minimal,
  metrics = metric_set(rmse, rsq, mae)
)

# Select the best model for each tuned model
best_lasso <- lasso_tuned %>% select_best(metric = "rmse")
best_tree <- tree_tuned %>% select_best(metric = "rmse")
best_bagged <- bagged_tuned %>% select_best(metric = "rmse")
best_rf <- rf_tuned %>% select_best(metric = "rmse")

# Finalize the workflows with the best models
final_lasso_workflow <- lasso_workflow %>% finalize_workflow(best_lasso)
final_tree_workflow <- tree_workflow %>% finalize_workflow(best_tree)
final_bagged_workflow <- bagged_workflow %>% finalize_workflow(best_bagged)
final_rf_workflow <- rf_workflow %>% finalize_workflow(best_rf)

# Fit the finalized models on the full training data
final_lasso_fit <- final_lasso_workflow %>% fit(data = bike_train)
final_tree_fit <- final_tree_workflow %>% fit(data = bike_train)
final_bagged_fit <- final_bagged_workflow %>% fit(data = bike_train)
final_rf_fit <- final_rf_workflow %>% fit(data = bike_train)
final_mlr_fit <- workflow3 %>% fit(data=bike_train)



library(yardstick)
library(purrr)

# Compare the models on the test set
# Compare the models on the test set
test_results <- bike_test %>%
  bind_cols(
    lasso_pred = predict(final_lasso_fit, new_data = bike_test)$.pred,
    tree_pred = predict(final_tree_fit, new_data = bike_test)$.pred,
    bagged_pred = predict(final_bagged_fit, new_data = bike_test)$.pred,
    rf_pred = predict(final_rf_fit, new_data = bike_test)$.pred,
   
  )

test_metrics <- imap_dfr(
  list(
    LASSO = test_results$lasso_pred,
    `Regression Tree` = test_results$tree_pred,
    `Bagged Tree` = test_results$bagged_pred,
    `Random Forest` = test_results$rf_pred
    
  ),
  ~ tibble(
    model = .y,
    rmse = rmse_vec(test_results$bike_count, .x),
    mae = mae_vec(test_results$bike_count, .x)
  )
)

# Select the best overall model
best_model <- test_metrics %>%
  arrange(rmse) %>%
  slice(1) %>%
  pull(model)

cat("The best overall model based on RMSE is:", best_model, "\n")

# Fit the best model on the entire dataset
best_fit <- switch(best_model,
                   "LASSO" = final_lasso_workflow,
                   "Regression Tree" = final_tree_workflow,
                   "Bagged Tree" = final_bagged_workflow,
                   "Random Forest" = final_rf_workflow,
                   
) %>%
  fit(data = bike_data_clean)








```
